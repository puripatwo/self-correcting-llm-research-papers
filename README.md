# Self-Correcting LLMs Research Papers 2024

## 1. Comics Generation
### 1.1. Stylized Art

### 1.2. Previous Work

## 2. Generative Models
### 2.1. GANs
[1] Generative Adversarial Networks [paper](https://arxiv.org/pdf/1406.2661)

### 2.2. Diffusion Models
[1] Denoising Diffusion Probabilistic Models [paper](https://arxiv.org/pdf/2006.11239)

## 3. Text-to-Image Generative Models
### 3.1. Text-to-Image Diffusion Models
[1] Training-Free Layout Control with Cross-Attention Guidance [paper](https://arxiv.org/pdf/2304.03373)

[2] GLIGEN: Open-Set Grounded Text-to-Image Generation [paper](https://arxiv.org/pdf/2301.07093)

[3] Localizing Object-level Shape Variations with Text-to-Image Diffusion Models [paper](https://arxiv.org/pdf/2303.11306)

[4] Paint by Example: Exemplar-based Image Editing with Diffusion Models [paper](https://arxiv.org/pdf/2211.13227)

[5] ReCo: Region-Controlled Text-to-Image Generation [paper](https://arxiv.org/pdf/2211.15518)

[6] LayoutGPT: Compositional Visual Planning and Generation with Large Language Models [paper](https://arxiv.org/pdf/2305.15393)

[7] LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models [paper](https://arxiv.org/pdf/2305.13655)

[8] LLM-GROUNDED VIDEO DIFFUSION MODELS [paper](https://arxiv.org/pdf/2309.17444)

[9] VIDEODIRECTORGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning [paper](https://arxiv.org/pdf/2309.15091)

[10] Controllable Text-to-Image Generation with GPT-4 [paper](https://arxiv.org/pdf/2305.18583)

### 3.2. Large Language Models
[1] Attention Is All You Need [paper](https://arxiv.org/pdf/1706.03762)

## 4. Self-Correcting Text-to-Image Generative Models
[1] Self-Correcting LLM-controlled Diffusion Models [paper](https://arxiv.org/pdf/2311.16090)

[2] Self-Consuming Models Go MAD [paper](https://arxiv.org/pdf/2307.01850)
 
[3] Self-Correcting Self-Consuming Loops for Generative Model Training [paper](https://arxiv.org/pdf/2402.07087)
 
[4] GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing [paper](https://arxiv.org/pdf/2407.05600)
 
[5] GG-Editor: Locally Editing 3D Avatars with Multimodal Large Language Model Guidance [paper](https://openreview.net/pdf?id=31rrsYnriG)

[6] Concept Sliders [paper](https://arxiv.org/pdf/2311.12092)

[7] Prompt Sliders for Fine-Grained Control, Editing and Erasing of Concepts in Diffusion Models [paper](https://arxiv.org/pdf/2409.16535)

[8] Adding Conditional Control to Text-to-Image Diffusion Models [paper](https://arxiv.org/pdf/2302.05543)
 
[9] Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects [paper](https://arxiv.org/pdf/2409.02653)

[10] A Survey on Self-Evolution of Large Language Models [paper](https://arxiv.org/pdf/2404.14387)
