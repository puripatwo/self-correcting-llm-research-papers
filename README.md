# Self-Correcting LLMs Research Papers 2024

## 1. Comics Generation
### 1.1. Stylized Art

### 1.2. Previous Work

## 2. Generative Models
### 2.1. GANs
[1] Generative Adversarial Networks [paper](https://arxiv.org/pdf/1406.2661)

[2] A Style-Based Generator Architecture for Generative Adversarial Networks [paper](https://arxiv.org/pdf/1812.04948)

### 2.2. Diffusion Models
[1] Denoising Diffusion Probabilistic Models [paper](https://arxiv.org/pdf/2006.11239)

[2] Diffusion Models Beat GANs on Image Synthesis [paper](https://arxiv.org/abs/2105.05233)

[3] SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis [paper](https://arxiv.org/pdf/2307.01952)

## 3. Text-to-Image Generative Models
### 3.1. Text-to-Image Diffusion Models
[1] High-Resolution Image Synthesis with Latent Diffusion Models [paper](https://arxiv.org/pdf/2112.10752)

[2] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding [paper](https://arxiv.org/abs/2205.11487)

[3] Training-Free Layout Control with Cross-Attention Guidance [paper](https://arxiv.org/pdf/2304.03373)

[4] GLIGEN: Open-Set Grounded Text-to-Image Generation [paper](https://arxiv.org/pdf/2301.07093)

[5] Localizing Object-level Shape Variations with Text-to-Image Diffusion Models [paper](https://arxiv.org/pdf/2303.11306)

[6] Paint by Example: Exemplar-based Image Editing with Diffusion Models [paper](https://arxiv.org/pdf/2211.13227)

[7] ReCo: Region-Controlled Text-to-Image Generation [paper](https://arxiv.org/pdf/2211.15518)

### 3.2. Large Language Models
[1] Attention Is All You Need [paper](https://arxiv.org/pdf/1706.03762)

[2] LayoutGPT: Compositional Visual Planning and Generation with Large Language Models [paper](https://arxiv.org/pdf/2305.15393)

[3] LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models [paper](https://arxiv.org/pdf/2305.13655)

[4] LLM-GROUNDED VIDEO DIFFUSION MODELS [paper](https://arxiv.org/pdf/2309.17444)

[5] VIDEODIRECTORGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning [paper](https://arxiv.org/pdf/2309.15091)

[6] Controllable Text-to-Image Generation with GPT-4 [paper](https://arxiv.org/pdf/2305.18583)

## 4. Self-Correcting Text-to-Image Generative Models
### 4.1. Self Correcting LLMs
[1] Self-Correcting LLM-controlled Diffusion Models [paper](https://arxiv.org/pdf/2311.16090)

[2] Self-Consuming Models Go MAD [paper](https://arxiv.org/pdf/2307.01850)
 
[3] Self-Correcting Self-Consuming Loops for Generative Model Training [paper](https://arxiv.org/pdf/2402.07087)
 
[4] GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing [paper](https://arxiv.org/pdf/2407.05600)
 
[5] GG-Editor: Locally Editing 3D Avatars with Multimodal Large Language Model Guidance [paper](https://openreview.net/pdf?id=31rrsYnriG)

[6] A Survey on Self-Evolution of Large Language Models [paper](https://arxiv.org/pdf/2404.14387)

### 4.2. Image Editing
[1] Concept Sliders [paper](https://arxiv.org/pdf/2311.12092)

[2] Prompt Sliders for Fine-Grained Control, Editing and Erasing of Concepts in Diffusion Models [paper](https://arxiv.org/pdf/2409.16535)

[3] Adding Conditional Control to Text-to-Image Diffusion Models [paper](https://arxiv.org/pdf/2302.05543)
 
[4] Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects [paper](https://arxiv.org/pdf/2409.02653)

[5] Prompt-to-Prompt Image Editing with Cross Attention Control [paper](https://arxiv.org/pdf/2208.01626)

[6] LoRA: Low-Rank Adaptation of Large Language Models [paper](https://arxiv.org/pdf/2106.09685)
